<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Diffusion Models · Project 4 Summary</title>
    <style>
      :root {
        --bg: #f8f8f6;
        --ink: #1d1f23;
        --muted: #5b616e;
        --line: #e3e3dd;
        --accent: #0055aa;
      }

      * {
        box-sizing: border-box;
        margin: 0;
        padding: 0;
      }

      body {
        font-family: "IBM Plex Sans", system-ui, -apple-system, BlinkMacSystemFont,
          "Segoe UI", sans-serif;
        background: var(--bg);
        color: var(--ink);
        line-height: 1.6;
        padding: 40px 20px 64px;
      }

      .page {
        max-width: 1100px;
        margin: 0 auto;
        background: #fff;
        border: 1px solid var(--line);
        border-radius: 20px;
        padding: 48px clamp(24px, 5vw, 72px);
        box-shadow: 0 12px 32px rgba(0, 0, 0, 0.05);
      }

      h1 {
        font-size: clamp(2rem, 4vw, 3rem);
        letter-spacing: -0.02em;
      }

      header p {
        margin-top: 12px;
        color: var(--muted);
      }

      section {
        margin-top: 48px;
      }

      h2 {
        font-size: 1.3rem;
        letter-spacing: 0.02em;
        margin-bottom: 12px;
      }

      .summary {
        border-left: 3px solid var(--accent);
        padding-left: 18px;
        color: var(--muted);
      }

      .grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
        gap: 16px;
        margin-top: 20px;
      }

      .stat {
        border: 1px solid var(--line);
        border-radius: 14px;
        padding: 18px;
      }

      .stat strong {
        font-size: 2rem;
        color: var(--accent);
        display: block;
      }

      ul {
        list-style: none;
        color: var(--muted);
      }

      ul li {
        padding: 10px 0;
        border-bottom: 1px solid var(--line);
      }

      .timeline {
        border-left: 2px solid var(--line);
        margin-top: 12px;
      }

      .stage {
        margin-left: 24px;
        padding: 16px 0;
      }

      .stage h3 {
        font-size: 1rem;
        margin-bottom: 6px;
      }

      .gallery {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(240px, 1fr));
        gap: 16px;
      }

      .gallery figure {
        border: 1px solid var(--line);
        border-radius: 16px;
        overflow: hidden;
        background: #fafafa;
      }

      .gallery img {
        width: 100%;
        display: block;
      }

      .gallery figcaption {
        padding: 10px 14px;
        font-size: 0.9rem;
        color: var(--muted);
      }

      .links {
        display: flex;
        flex-wrap: wrap;
        gap: 12px;
        margin-top: 16px;
      }

      .links a {
        text-decoration: none;
        color: var(--accent);
        border: 1px solid var(--accent);
        padding: 10px 16px;
        border-radius: 999px;
        font-weight: 500;
      }
    </style>
  </head>
  <body>
    <main class="page">
      <header>
        <h1>Diffusion Models · Project 4 Summary</h1>
        <p>
          Forward diffusion, classical filtering, neural denoisers, classifier‑free guidance, and
          SDEdit experiments executed with DeepFloyd IF. All image experiments share
          <code>torch.manual_seed(180)</code> for reproducibility.
        </p>
      </header>

      <section>
        <h2>Quick numbers</h2>
        <div class="grid">
          <div class="stat">
            <strong>3</strong>
            base prompts rendered in Part 0 using two inference-step budgets plus commentary.
          </div>
          <div class="stat">
            <strong>5</strong>
            CFG samples at γ = 7 comparing conditioned vs. unconditional noise predictions.
          </div>
          <div class="stat">
            <strong>6</strong>
            SDEdit starting indices (1 … 20) per image to illustrate edit strength.
          </div>
          <div class="stat">
            <strong>2</strong>
            custom assets (campanile, sea) reused across denoising and editing loops.
          </div>
        </div>
      </section>

      <section>
        <h2>Data & resources</h2>
        <p class="summary">
          Model weights: DeepFloyd IF stage 1/2 (FP16). Prompt embeddings cached in
          <code>prompt_embeds_dict.pth</code> to skip loading the large T5 encoder. Test imagery:
          <code>campanile.jpg</code> plus personal <code>dz.png</code> and <code>Sea images.png</code>.
        </p>
        <div class="links">
          <a href="Project_4.html">Full HTML export</a>
          <a href="Project_4_Summary.html">Condensed summary</a>
          <a href="Project_4 (3).py">Notebook script</a>
        </div>
      </section>

      <section>
        <h2>Work completed</h2>
        <div class="timeline">
          <div class="stage">
            <h3>Part 0 · model bring-up</h3>
            <ul>
              <li>Authenticated to Hugging Face, loaded both IF stages in FP16.</li>
              <li>Sampled three prompts at two inference-step counts and recorded observations.</li>
              <li>Captured the global seed (180) used everywhere else.</li>
            </ul>
          </div>
          <div class="stage">
            <h3>Part 1 · forward & reverse processes</h3>
            <ul>
              <li>Implemented the analytical forward process and visualized noise growth at t={250,500,750}.</li>
              <li>Compared Gaussian blur vs. stage‑1 UNet on the same noisy images.</li>
              <li>Created a 990→0 stride‑30 timetable and iterative denoiser (multi-step + single-step baselines).</li>
            </ul>
          </div>
          <div class="stage">
            <h3>Part 2 · sampling, CFG, SDEdit</h3>
            <ul>
              <li>Generated five unconditional samples via <code>iterative_denoise</code>.</li>
              <li>Added classifier-free guidance using empty prompt embeddings, γ = 7.</li>
              <li>Applied SDEdit to the campanile and two custom photos at starting indices {1,3,5,7,10,20}.</li>
            </ul>
          </div>
        </div>
      </section>

      <section>
        <h2>Image highlights</h2>
        <p class="summary">
          The gallery samples are written to <code>/images</code> during notebook export. Below are
          representative outputs from Part 0 (prompt sampling), Part 1 (forward/denoise), and Part 2 (CFG + SDEdit).
        </p>
        <div class="gallery">
          <figure>
            <img src="images/image_000.png" alt="Prompt sampling comparison" />
            <figcaption>Part 0 · stage 2 render (longer vs. shorter inference steps).</figcaption>
          </figure>
          <figure>
            <img src="images/image_002.png" alt="Forward diffusion noise levels" />
            <figcaption>Part 1.1 · Noise accumulation at t = 250/500/750 on campanile.jpg.</figcaption>
          </figure>
          <figure>
            <img src="images/image_004.png" alt="Iterative denoising progression" />
            <figcaption>Part 1.4 · Iterative denoise vs. one-step vs. Gaussian blur.</figcaption>
          </figure>
          <figure>
            <img src="images/image_006.png" alt="CFG sampling results" />
            <figcaption>Part 2.2 · Classifier-free guidance (γ = 7) “a high quality photo”.</figcaption>
          </figure>
          <figure>
            <img src="images/image_007.png" alt="SDEdit series" />
            <figcaption>Part 2.3 · SDEdit edits for custom sea photo at different noise starts.</figcaption>
          </figure>
        </div>
      </section>
    </main>
  </body>
</html>
